
<p align="center">
  <img src="app/assets/banner_chm.png" width="100%" />
</p>





### Proyecto final ‚Äì Modelos Transformer aplicados a Im√°genes

> Implementaci√≥n inspirada en el art√≠culo  
> **‚ÄúHigh-resolution canopy height maps by learning from airborne lidar and spaceborne GEDI‚Äù**  
> Repositorio original: https://github.com/facebookresearch/HighResCanopyHeight

---

## üìå Contexto y objetivo

El monitoreo forestal moderno necesita ir m√°s all√° del ‚Äúbosque / no bosque‚Äù y aproximarse a un **censo estructural del bosque**:  
- ¬øCu√°nta √°rea tiene √°rboles?  
- ¬øQu√© tan altos son esos √°rboles?  
- ¬øC√≥mo se distribuye la altura del dosel en el territorio?

El art√≠culo base propone un modelo capaz de **convertir im√°genes satelitales RGB de muy alta resoluci√≥n en mapas continuos de altura de dosel (~1 m)**, combinando informaci√≥n de:

- **LiDAR a√©reo (ALS)** ‚Üí detalle fino, pero cobertura limitada.
- **LiDAR satelital GEDI** ‚Üí cobertura casi global, pero resoluci√≥n (~25 m) y muestreo discreto (huellas).

Este proyecto reproduce y adapta ese enfoque usando **Transformers de visi√≥n pre-entrenados**, y construye una interfaz en **Streamlit** para explorar:

- M√©tricas cient√≠ficas (MAE, RMSE, R¬≤, sesgo, altura P95).
- M√©tricas de **‚Äúcenso estructural‚Äù** (altura promedio del dosel, % de √°rea con √°rboles, distribuci√≥n de alturas, etc.).

---


## üèóÔ∏è Resumen te√≥rico de la arquitectura

Aqu√≠ se resume la arquitectura completa en 3 niveles: **encoder SSL**, **decoder ALS** y **modelo GEDI + fusi√≥n**.

---

### 1. Encoder SSL: ViT Huge con DINOv2

<p align="center">
  <img src="app/assets/vit.png" width="60%" />
</p>


1. **Entrada**
   - Im√°genes satelitales globales de 256√ó256 p√≠xeles.
   - Se genera un **multi-crop**:
     - 2 vistas **globales**.
     - 8 vistas **locales** (algunas con m√°scara).

2. **Tokenizaci√≥n**
   - Cada imagen se divide en parches 16√ó16 ‚Üí se aplanan a vectores.
   - Se proyectan a un embedding de dimensi√≥n 1280 y se les suma un embedding posicional.

3. **Teacher‚ÄìStudent (DINOv2)**
   - Dos ViT con la misma arquitectura:

<p align="center">
  <img src="app/assets/vit2.png" width="100%" />
</p>

     - **Student**: recibe vistas globales + locales (con masking). Se actualiza por gradiente.
     - **Teacher**: recibe vistas globales, se actualiza por EMA (promedio m√≥vil de los pesos del student).
   - Las salidas del student intentan **imitar las del teacher** ‚Üí p√©rdida de auto-supervisi√≥n.
   - Al final de esta fase nos quedamos con el **encoder entrenado**, no con un mapa de salida.

---

### 2. Decoder DPT para CHM de alta resoluci√≥n (ALS)

<p align="center">
  <img src="app/assets/dpt.png" width="100%" />
</p>

A partir de aqu√≠, el encoder queda **congelado** y s√≥lo se entrena el decoder.

1. **Reassemble blocks**

<p align="center">
  <img src="app/assets/rem.png" width="60%" />
</p>

   - Toman las features del ViT en distintas capas y las transforman en mapas 2D a distintas escalas.
   - Cada bloque:
     - **Read**: reordena los tokens a su posici√≥n espacial ‚Üí mapa 2D.
     - **Concat + Project (Conv 1√ó1)**: apila canales y reduce/reorganiza la informaci√≥n.
     - **Resample‚Çõ**: ajusta el tama√±o del mapa para trabajar en escalas 1/32, 1/16, 1/8 y 1/4.

2. **Fusion blocks**

<p align="center">
  <img src="app/assets/fus.png" width="60%" />
</p>

   - Combinan informaci√≥n **global** (mapas m√°s peque√±os) con **detalle fino** (mapas de mayor resoluci√≥n).
   - Cada bloque:
     - Aplica una **Residual Conv Unit** para limpiar/refinar.
     - **Suma residual** entre el mapa global y el mapa m√°s fino.
     - Hace un **upsample √ó2** (Resample‚ÇÄ.5) para ir subiendo de resoluci√≥n.
     - Otro **Project (Conv 1√ó1)** adapta el n√∫mero de canales para el siguiente nivel.

3. **Head (salida por bins)**

<p align="center">
  <img src="app/assets/head.png" width="60%" />
</p>

   - Toma el √∫ltimo mapa de features (64√ó64) y:
     - Aplica un **upsample** para volver a 256√ó256.
     - Conv 1√ó1 ‚Üí genera **256 bins de altura por p√≠xel**.
     - Softmax ‚Üí histograma de probabilidad de altura por p√≠xel.
     - Promedio ponderado ‚Üí altura esperada en metros.
   - Se obtiene un **CHM predicho 256√ó256**, alineado con el tile de entrada.

4. **Funci√≥n de p√©rdida: Sigloss**


   - Variante de la p√©rdida de profundidad de Eigen et al.:
     - Trabaja en espacio logar√≠tmico.
     - Penaliza errores absolutos y errores globales de escala.
   - Se usa el **CHM ALS real** como verdad terreno.

---

### 3. Modelo GEDI global y fusi√≥n ALS + GEDI

<p align="center">
  <img src="app/assets/gedi.png" width="100%" />
</p>

1. **Modelo GEDI (CNN + metadata)**
<p align="center">
  <img src="app/assets/cnn.png" width="100%" />
</p>

   - Entrada:
     - Parche RGB de 128√ó128.
     - Metadatos: latitud, longitud, elevaci√≥n solar, √°ngulo off-nadir, pendiente del terreno.
   - Arquitectura:
     - **Extractor CNN** con varias capas Conv2D + ReLU + MaxPooling.
     - **Flatten ‚Üí capas densas**, donde se concatenan los metadatos.
   - Salida:
     - Un escalar: altura **RH95** (GEDI) en ese footprint.
   - P√©rdida:
   
     - **L1 Loss** entre altura predicha y altura medida por GEDI.

2. **C√°lculo de factor de reescalamiento**

<p align="center">
  <img src="app/assets/combi.png" width="100%" />
</p>
   - Se cruzan las predicciones del modelo ALS y del modelo GEDI en zonas con datos comunes.
   - Se calcula un **factor de escala espacialmente suave** que corrige el CHM ALS.

3. **CHM final**
   - El CHM ALS de alta resoluci√≥n se multiplica por el factor de reescalamiento.
   - Resultado: **canopy height map continuo**, detallado y coherente con GEDI a escala global.

---






### ‚öñÔ∏èüå≥ Descarga de pesos preentrenados 

Para que la aplicaci√≥n pueda realizar **inferencia real**, es indispensable descargar los **pesos preentrenados** del modelo original de Meta AI:  
**High-Resolution Canopy Height Maps**.



#### ¬øDe d√≥nde descargar los pesos?

1. Ve al repositorio original del proyecto (Meta / `HighResolutionCanopyHeight`).
2. Busca la secci√≥n de **model checkpoints / weights**.
3. Descarga, como m√≠nimo, los siguientes archivos:

- ‚úÖ **Checkpoint del modelo CHM**, por ejemplo:  
  `compressed_SSLhuge_aerial.pth`

- ‚úÖ **Pesos de la red de normalizaci√≥n RNet**, usados cuando `normtype = 2`.  
  El nombre del archivo debe coincidir con lo que espera la funci√≥n  
  `load_rnet_normalizer()` en `model/ssl_model.py`.


#### 3.2. D√≥nde ubicar los archivos descargados

Copia los archivos descargados en la carpeta:

```bash
saved_checkpoints/
```

---

### üöÄ Ejecuci√≥n del Proyecto con **Docker**
Instalaci√≥n ‚Ä¢ Despliegue ‚Ä¢ Uso

Este proyecto est√° preparado para ejecutarse f√°cilmente usando **Docker**, sin necesidad de instalar manualmente todas las dependencias en tu m√°quina local.



#### üìÅ Clonar el repositorio

```bash
git clone https://github.com/StevenVegaL/HighRes-Canopy-Height
cd HighResCanopyHeightApp
```

‚ö†Ô∏è Importante:
Antes de continuar, aseg√∫rate de que la carpeta saved_checkpoints/ contiene los pesos indicados en la secci√≥n anterior (modelo CHM y RNet).


#### üõ†Ô∏è Construir la imagen Docker
Desde la ra√≠z del proyecto, ejecuta:

```bash

docker build -t chm-demo .

```



üîé ¬øQu√© hace este comando?

Elemento	Descripci√≥n
-t chm-demo	Asigna el nombre chm-demo a la imagen Docker
.	Usa el Dockerfile ubicado en el directorio actual







####  ‚ñ∂Ô∏è Ejecutar el contenedor
Una vez construida la imagen, puedes levantar el contenedor con:

```bash
docker run -p 8501:8501 chm-demo
```


üí° Si el puerto 8501 ya est√° ocupado en tu m√°quina, puedes usar otro puerto externo, por ejemplo:

```bash
docker run -p 8502:8501 chm-demo
```




#### üåê Acceder a la aplicaci√≥n
Con el contenedor en ejecuci√≥n, abre tu navegador en:

```bash
http://localhost:8501
```
Deber√≠as ver la landing de la aplicaci√≥n.




---

### üíª Ejecuci√≥n local (opcional, sin Docker)

Aunque la forma recomendada de ejecutar el proyecto es mediante **Docker**, tambi√©n puedes correr la aplicaci√≥n **localmente** si ya tienes **Python** instalado en tu m√°quina.



#### üß¨ Crear entorno virtual e instalar dependencias

Se recomienda usar un entorno virtual para aislar las dependencias del proyecto.

#### 1Ô∏è‚É£ Crear y activar el entorno virtual

```bash
python -m venv .venv
```

En Windows:

```bash
.venv\Scripts\activate
```

En Linux / macOS:

```bash

source .venv/bin/activate
```

Ver√°s que el prompt de tu terminal cambia, indicando que el entorno .venv est√° activo.

2Ô∏è‚É£ Actualizar pip e instalar dependencias
Con el entorno virtual activado, ejecuta:

```bash
pip install --upgrade pip
pip install -r requirements.txt

```



#### üöÄ  Lanzar la aplicaci√≥n con Streamlit
Una vez instaladas las dependencias, desde la ra√≠z del proyecto ejecuta:

```bash

streamlit run app/streamlit_landing_CHM_app.py

```

Si todo est√° correctamente configurado (incluyendo los pesos en saved_checkpoints/), Streamlit levantar√° la aplicaci√≥n.

üåê Acceder a la app
Abre tu navegador y visita:

```bash
http://localhost:8501
```

All√≠ ceber√≠as ver la landing de la aplicaci√≥n.

---

### üß† Explicaci√≥n: ¬øc√≥mo se cargan los pesos y c√≥mo se realiza la inferencia?

La l√≥gica de carga de pesos y de inferencia est√° dividida en dos contextos:


#### üå≤ Modo NEON (dataset) ‚Äì usa RNet + NeonDataset.


#### üñºÔ∏è Modo de imagen subida ‚Äì usa solo el modelo CHM con normalizaci√≥n global.






---

## üìö Referencias

- Weinstein, B. G., et al. **High-resolution canopy height maps by learning from airborne lidar and spaceborne GEDI.**  
- Repositorio oficial: https://github.com/facebookresearch/HighResCanopyHeight
- Oquab, M., et al. **DINOv2: Learning robust visual features without supervision.**
- Ranftl, R., et al. **Vision Transformers for dense prediction (DPT).**
